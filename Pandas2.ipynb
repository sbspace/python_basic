{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3\n",
       "1       1\n",
       "2       3\n",
       "3       1\n",
       "4       3\n",
       "       ..\n",
       "1304    3\n",
       "1305    1\n",
       "1306    3\n",
       "1307    3\n",
       "1308    3\n",
       "Name: Pclass, Length: 1309, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# 파일 불러오기 (csv → DataFrame) \n",
    "\n",
    "titanic_df = pd.read_csv('titanic_train.csv')  # 같은 디렉토리 \n",
    "# csv_test = pd.read_csv('C:/Users/Administrator/Documents/Python/test_csv_file.csv') #다른 디렉토리\n",
    "\n",
    "titanic_df.head(3)\n",
    "titanic_df['Pclass'].value_counts()  # 지정된 칼럽의 데이터 값 별 건수를 반환, NULL 개수까지 새려면 dropna=Fa\n",
    "titanic_df['Pclass'] # 특정 컬럼으로 선정하면 Series 타입이됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# 데이터(DataFrame 형식의) 구조 및 통계값 등 파악 \\n\\nprint('type:',type(titanic_df),'shape:',titanic_df.shape,'\\n')\\ntitanic_df.info()  #칼럼 정보, 데이터 타입과 건수, Null 개수 등 파악가능\\ntitanic_df.describe()  # 숫자형 컬럼에 대해서 통계값을 보여줌\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# 데이터(DataFrame 형식의) 구조 및 통계값 등 파악 \n",
    "\n",
    "print('type:',type(titanic_df),'shape:',titanic_df.shape,'\\n')\n",
    "titanic_df.info()  #칼럼 정보, 데이터 타입과 건수, Null 개수 등 파악가능\n",
    "titanic_df.describe()  # 숫자형 컬럼에 대해서 통계값을 보여줌'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# DataFrame ↔ 리스트/ndarray/딕셔너리 간 상호변환\\n\\n# 리스트, 배열(ndarray),딕셔너리 → DataFrame \\n\\ncol = ['c1','c2','c3']\\nlist2 = [[1,2,3],[4,5,6]]\\narray2 = np.array(list2)\\n#print(list2, array2, sep='\\n')\\ndf_list2 = pd.DataFrame(list2, columns = col) # DataFrame 생성방식, 컬럼지정안하면 0,1,2...\\ndf_array2 = pd.DataFrame(array2, columns = col)\\nprint(df_list2, df_array2, sep='\\n')\\n\\ndict = {'c1':[1,4],'c2':[2,5],'c3':[3,6],'c4':[4,7] } # key 는 칼럼, value 는 데이터로 매핑됨 \\ndf_dict = pd.DataFrame(dict) # key를 컬럼, value를 데이터로 자동으로 인식함\\n\\n# DataFrame → 리스트, 배열(ndarray),딕셔너리\\ndf = titanic_df.copy()\\narray_df = df.values # values 를 활용한 ndarray 로의 변환 \\nprint(array_df, type(array_df), array_df.shape)\\n\\nlist3 = df.values.tolist() # ndarray 변환하고 list 로 변환 \\ndict3 = df.to_dict('list') # dictionary 로 변환하는 방법 , () 안의 argument 는 value 값 표기할 형식 \\nprint(list3, dict3, sep='\\n')\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# DataFrame ↔ 리스트/ndarray/딕셔너리 간 상호변환\n",
    "\n",
    "# 리스트, 배열(ndarray),딕셔너리 → DataFrame \n",
    "\n",
    "col = ['c1','c2','c3']\n",
    "list2 = [[1,2,3],[4,5,6]]\n",
    "array2 = np.array(list2)\n",
    "#print(list2, array2, sep='\\n')\n",
    "df_list2 = pd.DataFrame(list2, columns = col) # DataFrame 생성방식, 컬럼지정안하면 0,1,2...\n",
    "df_array2 = pd.DataFrame(array2, columns = col)\n",
    "print(df_list2, df_array2, sep='\\n')\n",
    "\n",
    "dict = {'c1':[1,4],'c2':[2,5],'c3':[3,6],'c4':[4,7] } # key 는 칼럼, value 는 데이터로 매핑됨 \n",
    "df_dict = pd.DataFrame(dict) # key를 컬럼, value를 데이터로 자동으로 인식함\n",
    "\n",
    "# DataFrame → 리스트, 배열(ndarray),딕셔너리\n",
    "df = titanic_df.copy()\n",
    "array_df = df.values # values 를 활용한 ndarray 로의 변환 \n",
    "print(array_df, type(array_df), array_df.shape)\n",
    "\n",
    "list3 = df.values.tolist() # ndarray 변환하고 list 로 변환 \n",
    "dict3 = df.to_dict('list') # dictionary 로 변환하는 방법 , () 안의 argument 는 value 값 표기할 형식 \n",
    "print(list3, dict3, sep='\\n')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# DataFrame 의 칼럼 수정/삭제 및 Index 개체 \\n\\ntitanic_df['Age_0']=0   # 생성 \\ntitanic_df['Age*2']=titanic_df['Age']*2\\ntitanic_df['Age*2']=titanic_df['Age*2']*2 # 수정\\ntitanic_dropdf = titanic_df.drop('Age_0',axis=1, inplace=True) # 컬럼삭제: axis=1\\ntitanic_dropdf = titanic_df.drop(1,axis=0) # 행삭제: axis=0\\ntitanic_df.head() # inplace 를 True로 하면 자기자신도 drop 함.. 그래서 Age_0 컬럼은 없고, index 1 은 살아있음\\n\\ntitanic_dropdf = titanic_df.drop(['Age','Age*2'], axis=1) # 여러 컬럼 삭제 \\ntitanic_dropdf = titanic_df.drop([0,1,2], axis=0) # 여러 행 삭제\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# DataFrame 의 칼럼 수정/삭제 및 Index 개체 \n",
    "\n",
    "titanic_df['Age_0']=0   # 생성 \n",
    "titanic_df['Age*2']=titanic_df['Age']*2\n",
    "titanic_df['Age*2']=titanic_df['Age*2']*2 # 수정\n",
    "titanic_dropdf = titanic_df.drop('Age_0',axis=1, inplace=True) # 컬럼삭제: axis=1\n",
    "titanic_dropdf = titanic_df.drop(1,axis=0) # 행삭제: axis=0\n",
    "titanic_df.head() # inplace 를 True로 하면 자기자신도 drop 함.. 그래서 Age_0 컬럼은 없고, index 1 은 살아있음\n",
    "\n",
    "titanic_dropdf = titanic_df.drop(['Age','Age*2'], axis=1) # 여러 컬럼 삭제 \n",
    "titanic_dropdf = titanic_df.drop([0,1,2], axis=0) # 여러 행 삭제'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# DataFrame 의 데이터 셀렉션/인덱싱 및 필터링 (loc,iloc)\\n\\n# Numpy 의 경우 [] 안에 슬라이싱, 인덱싱 등으로 데이터 셀렉션을 하지만, DataFrame 의 경우 [] 안에 컬럼명, 불린 인덱스로만 사용하는 것이 좋음 \\n\\ntitanic_df[titanic_df['Pclass'] == 3].head(3)  #불린 인덱싱 활용예시\\ntitanic_df[titanic_df['Age']>60][['Fare','Sex']].head(3)\\ntitanic_df[(titanic_df['Age']>60)&(titanic_df['Pclass']==1)&~(titanic_df['2urvived']==1)].head(3)\\n\\n# 혹은 loc (명칭기반), iloc(인덱스기반) 함수를 통해 데이터 셀렉션 수행\\n\\ndata = { 'Name':['song','kim','park'],\\n         'Year':[2001,2002,2003],\\n         'Gender':['M','M','F'] }\\n    \\ndata_df = pd.DataFrame(data, index=['one','two','three'])\\nprint(data_df)\\nprint(data_df.iloc[1,2]) # 'M' 반환\\nprint(data_df.iloc[0:2,[1,2]]) #iloc 안에 슬라이싱이나 리스트 사용가능\\n\\n# 맨 마지막 컬럼 가져오기 (=타깃 값), 맨마지막 컬럼 외 전부 가져오기 (=피처값) \\nprint(data_df.iloc[:,-1], data_df.iloc[:,:-1], sep='\\n') #자주 쓰임\\n\\nprint(data_df.loc['one':'three','Gender'])\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# DataFrame 의 데이터 셀렉션/인덱싱 및 필터링 (loc,iloc)\n",
    "\n",
    "# Numpy 의 경우 [] 안에 슬라이싱, 인덱싱 등으로 데이터 셀렉션을 하지만, DataFrame 의 경우 [] 안에 컬럼명, 불린 인덱스로만 사용하는 것이 좋음 \n",
    "\n",
    "titanic_df[titanic_df['Pclass'] == 3].head(3)  #불린 인덱싱 활용예시\n",
    "titanic_df[titanic_df['Age']>60][['Fare','Sex']].head(3)\n",
    "titanic_df[(titanic_df['Age']>60)&(titanic_df['Pclass']==1)&~(titanic_df['2urvived']==1)].head(3)\n",
    "\n",
    "# 혹은 loc (명칭기반), iloc(인덱스기반) 함수를 통해 데이터 셀렉션 수행\n",
    "\n",
    "data = { 'Name':['song','kim','park'],\n",
    "         'Year':[2001,2002,2003],\n",
    "         'Gender':['M','M','F'] }\n",
    "    \n",
    "data_df = pd.DataFrame(data, index=['one','two','three'])\n",
    "print(data_df)\n",
    "print(data_df.iloc[1,2]) # 'M' 반환\n",
    "print(data_df.iloc[0:2,[1,2]]) #iloc 안에 슬라이싱이나 리스트 사용가능\n",
    "\n",
    "# 맨 마지막 컬럼 가져오기 (=타깃 값), 맨마지막 컬럼 외 전부 가져오기 (=피처값) \n",
    "print(data_df.iloc[:,-1], data_df.iloc[:,:-1], sep='\\n') #자주 쓰임\n",
    "\n",
    "print(data_df.loc['one':'three','Gender'])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# 정렬, Aggregation, Groupby 활용방법\\n\\n# 컬럼기준 정렬방식\\ntitanic_df.sort_values(by=['Pclass','Age'],ascending=False).head(3)\\n\\n# Aggregation : min,max,sum,count 등등.. \\ntitanic_df[['Parch','Age']].sum()  # Series 형식으로 각 칼럼의 합 반환\\n\\n# agg() 함수의 활용 : 컬럼마다 다른 함수를 적용하는 방법 \\nagg_format = {'Age':'max', 'Pclass':'mean','Parch':'sum'}\\ntitanic_df.agg(agg_format) # Series 형식으로 각 컬럼에 지정한 함수로 계산한값 반환\\ntitanic_df.groupby('Pclass').agg(agg_format) #위에 값을 Pclass 의 value값 기준으로 계산해서 DataFrame으로 반환\\n\\n# Groupby\\ntt = titanic_df.groupby('Pclass')\\ntt[['2urvived','Age']].count()\\n\\n# agg() 함수의 활용 \\n#특정 컬럼으로 그루핑한뒤, 특정 컬럼에 대해 여러가지 agg 사용가능\\ntitanic_df.groupby('Sex')['Age'].agg((max,min)) # Sex에 따라 PassengerID 의 min,max 구해줌\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# 정렬, Aggregation, Groupby 활용방법\n",
    "\n",
    "# 컬럼기준 정렬방식\n",
    "titanic_df.sort_values(by=['Pclass','Age'],ascending=False).head(3)\n",
    "\n",
    "# Aggregation : min,max,sum,count 등등.. \n",
    "titanic_df[['Parch','Age']].sum()  # Series 형식으로 각 칼럼의 합 반환\n",
    "\n",
    "# agg() 함수의 활용 : 컬럼마다 다른 함수를 적용하는 방법 \n",
    "agg_format = {'Age':'max', 'Pclass':'mean','Parch':'sum'}\n",
    "titanic_df.agg(agg_format) # Series 형식으로 각 컬럼에 지정한 함수로 계산한값 반환\n",
    "titanic_df.groupby('Pclass').agg(agg_format) #위에 값을 Pclass 의 value값 기준으로 계산해서 DataFrame으로 반환\n",
    "\n",
    "# Groupby\n",
    "tt = titanic_df.groupby('Pclass')\n",
    "tt[['2urvived','Age']].count()\n",
    "\n",
    "# agg() 함수의 활용 \n",
    "#특정 컬럼으로 그루핑한뒤, 특정 컬럼에 대해 여러가지 agg 사용가능\n",
    "titanic_df.groupby('Sex')['Age'].agg((max,min)) # Sex에 따라 PassengerID 의 min,max 구해줌'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# 결손 데이터 처리 (NULL = 넘파이에서는 NaN) \\n\\n# NaN 갯수 구하기 \\ntitanic_df.isna().sum() # 각 컬럼별 null 개수를 Seires 형태로 반환 \\n\\n# NaN 을 평균값으로 치환하기 \\ntitanic_df['Age']=titanic_df['Age'].fillna(titanic_df['Age'].mean())\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# 결손 데이터 처리 (NULL = 넘파이에서는 NaN) \n",
    "\n",
    "# NaN 갯수 구하기 \n",
    "titanic_df.isna().sum() # 각 컬럼별 null 개수를 Seires 형태로 반환 \n",
    "\n",
    "# NaN 을 평균값으로 치환하기 \n",
    "titanic_df['Age']=titanic_df['Age'].fillna(titanic_df['Age'].mean())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Pandas(DataFrame) 에서 apply lambda 활용법\\n\\nlambda_square = lambda x : x**2\\nprint(lambda_square(3))\\n# lambda 에 여러개 인풋 넣는방법\\n\\na = (1,2,3)\\nmulti5 = map(lambda x : x*5, a)\\nlist(multi5)\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Pandas(DataFrame) 에서 apply lambda 활용법\n",
    "\n",
    "lambda_square = lambda x : x**2\n",
    "print(lambda_square(3))\n",
    "# lambda 에 여러개 인풋 넣는방법\n",
    "\n",
    "a = (1,2,3)\n",
    "multi5 = map(lambda x : x*5, a)\n",
    "list(multi5)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# dataframe 에서 lamba 활용한 컬럼 생성 : apply()\\ntitanic_df['Name_len']=titanic_df['Name'].apply(lambda x:len(x))\\ntitanic_df[['Name_len','Name']].head(3)\\n\\n# if-else 조건절 활용한 labmda \\ntitanic_df['Age_Cate'] = titanic_df['Age'].apply(lambda x: 'Child' if x <=25 else ('Adult' if x<=35 else 'Elderly'))\\ntitanic_df[['Age_Cate','Age']].head(5)\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "# dataframe 에서 lamba 활용한 컬럼 생성 : apply()\n",
    "titanic_df['Name_len']=titanic_df['Name'].apply(lambda x:len(x))\n",
    "titanic_df[['Name_len','Name']].head(3)\n",
    "\n",
    "# if-else 조건절 활용한 labmda \n",
    "titanic_df['Age_Cate'] = titanic_df['Age'].apply(lambda x: 'Child' if x <=25 else ('Adult' if x<=35 else 'Elderly'))\n",
    "titanic_df[['Age_Cate','Age']].head(5)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
